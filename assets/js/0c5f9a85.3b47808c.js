"use strict";(self.webpackChunklangflow_docs=self.webpackChunklangflow_docs||[]).push([[9366],{7293:(e,n,o)=>{o.d(n,{A:()=>w});var s=o(6540),t=o(4848);function l(e){const{mdxAdmonitionTitle:n,rest:o}=function(e){const n=s.Children.toArray(e),o=n.find((e=>s.isValidElement(e)&&"mdxAdmonitionTitle"===e.type)),l=n.filter((e=>e!==o)),i=o?.props.children;return{mdxAdmonitionTitle:i,rest:l.length>0?(0,t.jsx)(t.Fragment,{children:l}):null}}(e.children),l=e.title??n;return{...e,...l&&{title:l},children:o}}var i=o(8215),r=o(1312),c=o(7559);const d={admonition:"admonition_xJq3",admonitionHeading:"admonitionHeading_Gvgb",admonitionIcon:"admonitionIcon_Rf37",admonitionContent:"admonitionContent_BuS1"};function a(e){let{type:n,className:o,children:s}=e;return(0,t.jsx)("div",{className:(0,i.A)(c.G.common.admonition,c.G.common.admonitionType(n),d.admonition,o),children:s})}function h(e){let{icon:n,title:o}=e;return(0,t.jsxs)("div",{className:d.admonitionHeading,children:[(0,t.jsx)("span",{className:d.admonitionIcon,children:n}),o]})}function p(e){let{children:n}=e;return n?(0,t.jsx)("div",{className:d.admonitionContent,children:n}):null}function x(e){const{type:n,icon:o,title:s,children:l,className:i}=e;return(0,t.jsxs)(a,{type:n,className:i,children:[s||o?(0,t.jsx)(h,{title:s,icon:o}):null,(0,t.jsx)(p,{children:l})]})}function j(e){return(0,t.jsx)("svg",{viewBox:"0 0 14 16",...e,children:(0,t.jsx)("path",{fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"})})}const g={icon:(0,t.jsx)(j,{}),title:(0,t.jsx)(r.A,{id:"theme.admonition.note",description:"The default label used for the Note admonition (:::note)",children:"note"})};function u(e){return(0,t.jsx)(x,{...g,...e,className:(0,i.A)("alert alert--secondary",e.className),children:e.children})}function m(e){return(0,t.jsx)("svg",{viewBox:"0 0 12 16",...e,children:(0,t.jsx)("path",{fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"})})}const f={icon:(0,t.jsx)(m,{}),title:(0,t.jsx)(r.A,{id:"theme.admonition.tip",description:"The default label used for the Tip admonition (:::tip)",children:"tip"})};function C(e){return(0,t.jsx)(x,{...f,...e,className:(0,i.A)("alert alert--success",e.className),children:e.children})}function F(e){return(0,t.jsx)("svg",{viewBox:"0 0 14 16",...e,children:(0,t.jsx)("path",{fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"})})}const y={icon:(0,t.jsx)(F,{}),title:(0,t.jsx)(r.A,{id:"theme.admonition.info",description:"The default label used for the Info admonition (:::info)",children:"info"})};function A(e){return(0,t.jsx)(x,{...y,...e,className:(0,i.A)("alert alert--info",e.className),children:e.children})}function I(e){return(0,t.jsx)("svg",{viewBox:"0 0 16 16",...e,children:(0,t.jsx)("path",{fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"})})}const k={icon:(0,t.jsx)(I,{}),title:(0,t.jsx)(r.A,{id:"theme.admonition.warning",description:"The default label used for the Warning admonition (:::warning)",children:"warning"})};function D(e){return(0,t.jsx)("svg",{viewBox:"0 0 12 16",...e,children:(0,t.jsx)("path",{fillRule:"evenodd",d:"M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"})})}const v={icon:(0,t.jsx)(D,{}),title:(0,t.jsx)(r.A,{id:"theme.admonition.danger",description:"The default label used for the Danger admonition (:::danger)",children:"danger"})};const b={icon:(0,t.jsx)(I,{}),title:(0,t.jsx)(r.A,{id:"theme.admonition.caution",description:"The default label used for the Caution admonition (:::caution)",children:"caution"})};const T={...{note:u,tip:C,info:A,warning:function(e){return(0,t.jsx)(x,{...k,...e,className:(0,i.A)("alert alert--warning",e.className),children:e.children})},danger:function(e){return(0,t.jsx)(x,{...v,...e,className:(0,i.A)("alert alert--danger",e.className),children:e.children})}},...{secondary:e=>(0,t.jsx)(u,{title:"secondary",...e}),important:e=>(0,t.jsx)(A,{title:"important",...e}),success:e=>(0,t.jsx)(C,{title:"success",...e}),caution:function(e){return(0,t.jsx)(x,{...b,...e,className:(0,i.A)("alert alert--warning",e.className),children:e.children})}}};var O=o(6763);function w(e){const n=l(e),o=(s=n.type,T[s]||(O.warn(`No admonition component found for admonition type "${s}". Using Info as fallback.`),T.info));var s;return(0,t.jsx)(o,{...n})}},6462:(e,n,o)=>{o.r(n),o.d(n,{CH:()=>h,assets:()=>a,chCodeConfig:()=>p,contentTitle:()=>c,default:()=>g,frontMatter:()=>r,metadata:()=>d,toc:()=>x});o(6540);var s=o(4848),t=o(8453),l=o(4754),i=o(7293);const r={},c="Models",d={id:"components/models",title:"Models",description:"This page may contain outdated information. It will be updated as soon as possible.",source:"@site/docs/components/models.mdx",sourceDirName:"components",slug:"/components/models",permalink:"/components/models",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Data",permalink:"/components/data"},next:{title:"Helpers",permalink:"/components/helpers"}},a={},h={annotations:l.hk,InlineCode:l.R0},p={staticMediaQuery:"not screen, (max-width: 768px)",lineNumbers:!0,showCopyButton:!0,themeName:"github-dark"},x=[{value:"Amazon Bedrock",id:"amazon-bedrock",level:2},{value:"Anthropic",id:"anthropic",level:2},{value:"Azure OpenAI",id:"azure-openai",level:2},{value:"Cohere",id:"cohere",level:2},{value:"Google Generative AI",id:"google-generative-ai",level:2},{value:"Hugging Face API",id:"hugging-face-api",level:2},{value:"LiteLLM Model",id:"litellm-model",level:2},{value:"Ollama",id:"ollama",level:2},{value:"OpenAI",id:"openai",level:2},{value:"Qianfan",id:"qianfan",level:2},{value:"Vertex AI",id:"vertex-ai",level:2}];function j(e){const n=Object.assign({h1:"h1",p:"p",h2:"h2",strong:"strong",ul:"ul",li:"li",hr:"hr",a:"a",code:"code"},(0,t.RP)(),e.components);return h||u("CH",!1),h.InlineCode||u("CH.InlineCode",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)("style",{dangerouslySetInnerHTML:{__html:'[data-ch-theme="github-dark"] {  --ch-t-colorScheme: dark;--ch-t-foreground: #c9d1d9;--ch-t-background: #0d1117;--ch-t-lighter-inlineBackground: #0d1117e6;--ch-t-editor-background: #0d1117;--ch-t-editor-foreground: #c9d1d9;--ch-t-editor-lineHighlightBackground: #6e76811a;--ch-t-editor-rangeHighlightBackground: #ffffff0b;--ch-t-editor-infoForeground: #3794FF;--ch-t-editor-selectionBackground: #264F78;--ch-t-focusBorder: #1f6feb;--ch-t-tab-activeBackground: #0d1117;--ch-t-tab-activeForeground: #c9d1d9;--ch-t-tab-inactiveBackground: #010409;--ch-t-tab-inactiveForeground: #8b949e;--ch-t-tab-border: #30363d;--ch-t-tab-activeBorder: #0d1117;--ch-t-editorGroup-border: #30363d;--ch-t-editorGroupHeader-tabsBackground: #010409;--ch-t-editorLineNumber-foreground: #6e7681;--ch-t-input-background: #0d1117;--ch-t-input-foreground: #c9d1d9;--ch-t-input-border: #30363d;--ch-t-icon-foreground: #8b949e;--ch-t-sideBar-background: #010409;--ch-t-sideBar-foreground: #c9d1d9;--ch-t-sideBar-border: #30363d;--ch-t-list-activeSelectionBackground: #6e768166;--ch-t-list-activeSelectionForeground: #c9d1d9;--ch-t-list-hoverBackground: #6e76811a;--ch-t-list-hoverForeground: #c9d1d9; }'}}),"\n","\n","\n",(0,s.jsx)(n.h1,{id:"models",children:"Models"}),"\n",(0,s.jsx)(i.A,{type:"warning",title:"warning",children:(0,s.jsx)(n.p,{children:"This page may contain outdated information. It will be updated as soon as possible."})}),"\n",(0,s.jsx)(n.h2,{id:"amazon-bedrock",children:"Amazon Bedrock"}),"\n",(0,s.jsx)(n.p,{children:"This component facilitates the generation of text using the LLM (Large Language Model) model from Amazon Bedrock."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input Value:"})," Specifies the input text for text generation."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"System Message (Optional):"})," A system message to pass to the model."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Model ID (Optional):"})," Specifies the model ID to be used for text generation. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"anthropic.claude-instant-v1"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"anthropic.claude-instant-v1"'}),". Available options include:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"ai21.j2-grande-instruct"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"ai21.j2-grande-instruct"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"ai21.j2-jumbo-instruct"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"ai21.j2-jumbo-instruct"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"ai21.j2-mid"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"ai21.j2-mid"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"ai21.j2-mid-v1"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"ai21.j2-mid-v1"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"ai21.j2-ultra"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"ai21.j2-ultra"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"ai21.j2-ultra-v1"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"ai21.j2-ultra-v1"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"anthropic.claude-instant-v1"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"anthropic.claude-instant-v1"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"anthropic.claude-v1"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"anthropic.claude-v1"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"anthropic.claude-v2"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"anthropic.claude-v2"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"cohere.command-text-v14"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"cohere.command-text-v14"'})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Credentials Profile Name (Optional):"})," Specifies the name of the credentials profile."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Region Name (Optional):"})," Specifies the region name."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Model Kwargs (Optional):"})," Additional keyword arguments for the model."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Endpoint URL (Optional):"})," Specifies the endpoint URL."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Streaming (Optional):"})," Specifies whether to stream the response from the model. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"False",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"False"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Cache (Optional):"})," Specifies whether to cache the response."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Stream (Optional):"})," Specifies whether to stream the response from the model. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"False",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"False"}),"."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.A,{type:"note",title:"Note",children:(0,s.jsx)("p",{children:(0,s.jsx)(n.p,{children:"Ensure that necessary credentials are provided to connect to the Amazon\nBedrock API. If connection fails, a ValueError will be raised."})})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"anthropic",children:"Anthropic"}),"\n",(0,s.jsx)(n.p,{children:"This component allows the generation of text using Anthropic Chat&Completion large language models."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Model Name:"})," Specifies the name of the Anthropic model to be used for text generation. Available options include:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"claude-2.1"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"claude-2.1"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"claude-2.0"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"claude-2.0"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"claude-instant-1.2"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"claude-instant-1.2"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"claude-instant-1"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"claude-instant-1"'})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Anthropic API Key:"})," Your Anthropic API key."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Max Tokens (Optional):"})," Specifies the maximum number of tokens to generate. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"256",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"256"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Temperature (Optional):"})," Specifies the sampling temperature. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"0.7",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"0.7"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"API Endpoint (Optional):"})," Specifies the endpoint of the Anthropic API. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"https://api.anthropic.com"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"https://api.anthropic.com"'})," if not specified."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input Value:"})," Specifies the input text for text generation."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Stream (Optional):"})," Specifies whether to stream the response from the model. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"False",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"False"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"System Message (Optional):"})," A system message to pass to the model."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["For detailed documentation and integration guides, please refer to the ",(0,s.jsx)(n.a,{href:"https://python.langchain.com/docs/integrations/chat/anthropic",children:"Anthropic Component Documentation"}),"."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"azure-openai",children:"Azure OpenAI"}),"\n",(0,s.jsx)(n.p,{children:"This component allows the generation of text using the LLM (Large Language Model) model from Azure OpenAI."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Model Name:"})," Specifies the name of the Azure OpenAI model to be used for text generation. Available options include:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"gpt-35-turbo"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"gpt-35-turbo"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"gpt-35-turbo-16k"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"gpt-35-turbo-16k"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"gpt-35-turbo-instruct"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"gpt-35-turbo-instruct"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"gpt-4"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"gpt-4"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"gpt-4-32k"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"gpt-4-32k"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"gpt-4-vision"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"gpt-4-vision"'})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Azure Endpoint:"})," Your Azure endpoint, including the resource. Example: ",(0,s.jsx)(n.code,{children:"https://example-resource.azure.openai.com/"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Deployment Name:"})," Specifies the name of the deployment."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"API Version:"})," Specifies the version of the Azure OpenAI API to be used. Available options include:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"2023-03-15-preview"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"2023-03-15-preview"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"2023-05-15"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"2023-05-15"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"2023-06-01-preview"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"2023-06-01-preview"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"2023-07-01-preview"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"2023-07-01-preview"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"2023-08-01-preview"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"2023-08-01-preview"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"2023-09-01-preview"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"2023-09-01-preview"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"2023-12-01-preview"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"2023-12-01-preview"'})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"API Key:"})," Your Azure OpenAI API key."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Temperature (Optional):"})," Specifies the sampling temperature. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"0.7",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"0.7"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Max Tokens (Optional):"})," Specifies the maximum number of tokens to generate. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"1000",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"1000"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input Value:"})," Specifies the input text for text generation."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Stream (Optional):"})," Specifies whether to stream the response from the model. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"False",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"False"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"System Message (Optional):"})," A system message to pass to the model."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["For detailed documentation and integration guides, please refer to the ",(0,s.jsx)(n.a,{href:"https://python.langchain.com/docs/integrations/llms/azure_openai",children:"Azure OpenAI Component Documentation"}),"."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"cohere",children:"Cohere"}),"\n",(0,s.jsx)(n.p,{children:"This component enables text generation using Cohere large language models."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Cohere API Key:"})," Your Cohere API key."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Max Tokens (Optional):"})," Specifies the maximum number of tokens to generate. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"256",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"256"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Temperature (Optional):"})," Specifies the sampling temperature. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"0.75",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"0.75"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input Value:"})," Specifies the input text for text generation."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Stream (Optional):"})," Specifies whether to stream the response from the model. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"False",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"False"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"System Message (Optional):"})," A system message to pass to the model."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"google-generative-ai",children:"Google Generative AI"}),"\n",(0,s.jsx)(n.p,{children:"This component enables text generation using Google Generative AI."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Google API Key:"})," Your Google API key to use for the Google Generative AI."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Model:"})," The name of the model to use. Supported examples are ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"gemini-pro"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"gemini-pro"'})," and ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"gemini-pro-vision"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"gemini-pro-vision"'}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Max Output Tokens (Optional):"})," The maximum number of tokens to generate."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Temperature:"})," Run inference with this temperature. Must be in the closed interval [0.0, 1.0]."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Top K (Optional):"})," Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Top P (Optional):"})," The maximum cumulative probability of tokens to consider when sampling."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"N (Optional):"})," Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input Value:"})," The input to the model."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Stream (Optional):"})," Specifies whether to stream the response from the model. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"False",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"False"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"System Message (Optional):"})," A system message to pass to the model."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"hugging-face-api",children:"Hugging Face API"}),"\n",(0,s.jsx)(n.p,{children:"This component facilitates text generation using LLM models from the Hugging Face Inference API."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Endpoint URL:"})," The URL of the Hugging Face Inference API endpoint. Should be provided along with necessary authentication credentials."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Task:"})," Specifies the task for text generation. Options include ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"text2text-generation"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"text2text-generation"'}),", ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"text-generation"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"text-generation"'}),", and ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"summarization"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"summarization"'}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"API Token:"})," The API token required for authentication with the Hugging Face Hub."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Model Keyword Arguments (Optional):"})," Additional keyword arguments for the model. Should be provided as a Python dictionary."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input Value:"})," The input text for text generation."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Stream (Optional):"})," Specifies whether to stream the response from the model. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"False",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"False"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"System Message (Optional):"})," A system message to pass to the model."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"litellm-model",children:"LiteLLM Model"}),"\n",(0,s.jsxs)(n.p,{children:["Generates text using the ",(0,s.jsx)(n.code,{children:"LiteLLM"})," collection of large language models."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Model name:"})," The name of the model to use. For example, ",(0,s.jsx)(n.code,{children:"gpt-3.5-turbo"}),". (Type: str)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"API key:"})," The API key to use for accessing the provider's API. (Type: str, Optional)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Provider:"}),' The provider of the API key. (Type: str, Choices: "OpenAI", "Azure", "Anthropic", "Replicate", "Cohere", "OpenRouter")']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Temperature:"})," Controls the randomness of the text generation. (Type: float, Default: 0.7)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Model kwargs:"})," Additional keyword arguments for the model. (Type: Dict, Optional)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Top p:"})," Filter responses to keep the cumulative probability within the top p tokens. (Type: float, Optional)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Top k:"})," Filter responses to only include the top k tokens. (Type: int, Optional)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"N:"})," Number of chat completions to generate for each prompt. (Type: int, Default: 1)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Max tokens:"})," The maximum number of tokens to generate for each chat completion. (Type: int, Default: 256)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Max retries:"})," Maximum number of retries for failed requests. (Type: int, Default: 6)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Verbose:"})," Whether to print verbose output. (Type: bool, Default: False)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input:"})," The input prompt for text generation. (Type: str)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Stream:"})," Whether to stream the output. (Type: bool, Default: False)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"System message:"})," System message to pass to the model. (Type: str, Optional)"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"ollama",children:"Ollama"}),"\n",(0,s.jsx)(n.p,{children:"Generate text using Ollama Local LLMs."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Base URL:"})," Endpoint of the Ollama API. Defaults to '",(0,s.jsx)(n.a,{href:"http://localhost:11434",children:"http://localhost:11434"}),"' if not specified."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Model Name:"})," The model name to use. Refer to ",(0,s.jsx)(n.a,{href:"https://ollama.ai/library",children:"Ollama Library"})," for more models."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Temperature:"})," Controls the creativity of model responses. (Default: 0.8)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Cache:"})," Enable or disable caching. (Default: False)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Format:"})," Specify the format of the output (e.g., json). (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Metadata:"})," Metadata to add to the run trace. (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Mirostat:"})," Enable/disable Mirostat sampling for controlling perplexity. (Default: Disabled)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Mirostat Eta:"})," Learning rate for Mirostat algorithm. (Default: None) (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Mirostat Tau:"})," Controls the balance between coherence and diversity of the output. (Default: None) (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Context Window Size:"})," Size of the context window for generating tokens. (Default: None) (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Number of GPUs:"})," Number of GPUs to use for computation. (Default: None) (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Number of Threads:"})," Number of threads to use during computation. (Default: None) (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Repeat Last N:"})," How far back the model looks to prevent repetition. (Default: None) (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Repeat Penalty:"})," Penalty for repetitions in generated text. (Default: None) (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"TFS Z:"})," Tail free sampling value. (Default: None) (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Timeout:"})," Timeout for the request stream. (Default: None) (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Top K:"})," Limits token selection to top K. (Default: None) (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Top P:"})," Works together with top-k. (Default: None) (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Verbose:"})," Whether to print out response text."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Tags:"})," Tags to add to the run trace. (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Stop Tokens:"})," List of tokens to signal the model to stop generating text. (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"System:"})," System to use for generating text. (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Template:"})," Template to use for generating text. (Advanced)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input:"})," The input text."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Stream:"})," Whether to stream the response."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"System Message:"})," System message to pass to the model. (Advanced)"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"openai",children:"OpenAI"}),"\n",(0,s.jsx)(n.p,{children:"This component facilitates text generation using OpenAI's models."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input Value:"})," The input text for text generation."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Max Tokens (Optional):"})," The maximum number of tokens to generate. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"256",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"256"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Model Kwargs (Optional):"})," Additional keyword arguments for the model. Should be provided as a nested dictionary."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Model Name (Optional):"})," The name of the model to use. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"gpt",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"4",props:{style:{color:"#79C0FF"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"1106",props:{style:{color:"#79C0FF"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"preview",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"gpt-4-1106-preview"}),". Supported options include: ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"gpt",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"4",props:{style:{color:"#79C0FF"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"turbo",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"preview",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"gpt-4-turbo-preview"}),", ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"gpt",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"4",props:{style:{color:"#79C0FF"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"0125",props:{style:{color:"#79C0FF"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"preview",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"gpt-4-0125-preview"}),", ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"gpt",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"4",props:{style:{color:"#79C0FF"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"1106",props:{style:{color:"#79C0FF"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"preview",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"gpt-4-1106-preview"}),", ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"gpt",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"4",props:{style:{color:"#79C0FF"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"vision",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"preview",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"gpt-4-vision-preview"}),", ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"gpt",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"3.5",props:{style:{color:"#79C0FF"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"turbo",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"0125",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"gpt-3.5-turbo-0125"}),", ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"gpt",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"3.5",props:{style:{color:"#79C0FF"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"turbo",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"1106",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"gpt-3.5-turbo-1106"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"OpenAI API Base (Optional):"})," The base URL of the OpenAI API. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"https",props:{style:{color:"#FFA657"}}},{content:":",props:{style:{color:"#C9D1D9"}}},{content:"//api.openai.com/v1",props:{style:{color:"#8B949E"}}}]}],lang:"jsx"},children:"https://api.openai.com/v1"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"OpenAI API Key (Optional):"})," The API key for accessing the OpenAI API."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Temperature:"})," Controls the creativity of model responses. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"0.7",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"0.7"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Stream (Optional):"})," Specifies whether to stream the response from the model. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"False",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"False"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"System Message (Optional):"})," System message to pass to the model."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"qianfan",children:"Qianfan"}),"\n",(0,s.jsx)(n.p,{children:"This component facilitates the generation of text using Baidu Qianfan chat models."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Model Name:"})," Specifies the name of the Qianfan chat model to be used for text generation. Available options include:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"ERNIE-Bot"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"ERNIE-Bot"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"ERNIE-Bot-turbo"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"ERNIE-Bot-turbo"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"BLOOMZ-7B"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"BLOOMZ-7B"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"Llama-2-7b-chat"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"Llama-2-7b-chat"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"Llama-2-13b-chat"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"Llama-2-13b-chat"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"Llama-2-70b-chat"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"Llama-2-70b-chat"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"Qianfan-BLOOMZ-7B-compressed"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"Qianfan-BLOOMZ-7B-compressed"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"Qianfan-Chinese-Llama-2-7B"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"Qianfan-Chinese-Llama-2-7B"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"ChatGLM2-6B-32K"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"ChatGLM2-6B-32K"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:'"AquilaChat-7B"',props:{style:{color:"#A5D6FF"}}}]}],lang:"jsx"},children:'"AquilaChat-7B"'})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Qianfan Ak:"})," Your Baidu Qianfan access key, obtainable from ",(0,s.jsx)(n.a,{href:"https://cloud.baidu.com/product/wenxinworkshop",children:"here"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Qianfan Sk:"})," Your Baidu Qianfan secret key, obtainable from ",(0,s.jsx)(n.a,{href:"https://cloud.baidu.com/product/wenxinworkshop",children:"here"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Top p (Optional):"})," Model parameter. Specifies the top-p value. Only supported in ERNIE-Bot and ERNIE-Bot-turbo models. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"0.8",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"0.8"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Temperature (Optional):"})," Model parameter. Specifies the sampling temperature. Only supported in ERNIE-Bot and ERNIE-Bot-turbo models. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"0.95",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"0.95"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Penalty Score (Optional):"})," Model parameter. Specifies the penalty score. Only supported in ERNIE-Bot and ERNIE-Bot-turbo models. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"1.0",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"1.0"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Endpoint (Optional):"})," Endpoint of the Qianfan LLM, required if custom model is used."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input Value:"})," Specifies the input text for text generation."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Stream (Optional):"})," Specifies whether to stream the response from the model. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"False",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"False"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"System Message (Optional):"})," A system message to pass to the model."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"vertex-ai",children:"Vertex AI"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"ChatVertexAI"})," is a component for generating text using Vertex AI Chat large language models API."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Credentials:"})," The JSON file containing the credentials for accessing the Vertex AI Chat API."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Project:"})," The name of the project associated with the Vertex AI Chat API."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Examples (Optional):"})," List of examples to provide context for text generation."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Location:"})," The location of the Vertex AI Chat API service. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"us",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"central1",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"us-central1"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Max Output Tokens:"})," The maximum number of tokens to generate. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"128",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"128"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Model Name:"})," The name of the model to use. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"chat",props:{style:{color:"#C9D1D9"}}},{content:"-",props:{style:{color:"#FF7B72"}}},{content:"bison",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"chat-bison"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Temperature:"})," Controls the creativity of model responses. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"0.0",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"0.0"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input Value:"})," The input text for text generation."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Top K:"})," Limits token selection to top K. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"40",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"40"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Top P:"})," Works together with top-k. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"0.95",props:{style:{color:"#79C0FF"}}}]}],lang:"jsx"},children:"0.95"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Verbose:"})," Whether to print out response text. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"False",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"False"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Stream (Optional):"})," Specifies whether to stream the response from the model. Defaults to ",(0,s.jsx)(h.InlineCode,{codeConfig:p,code:{lines:[{tokens:[{content:"False",props:{style:{color:"#C9D1D9"}}}]}],lang:"jsx"},children:"False"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"System Message (Optional):"})," System message to pass to the model."]}),"\n"]}),"\n"]})]})}const g=function(e={}){const{wrapper:n}=Object.assign({},(0,t.RP)(),e.components);return n?(0,s.jsx)(n,Object.assign({},e,{children:(0,s.jsx)(j,e)})):j(e)};function u(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}}}]);